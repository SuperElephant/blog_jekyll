---
layout: post
title: "[Notes] CSCI 585 discussion 9 ML
"
tags: [csci585, eng, note]
excerpt_separator: ---
---

ML

---

So, what's the BFD about ML? :)
- predicting: training, deploying 

(2014) The Unreasonable Effectiveness of Deep Learning: https://www.cs.tau.ac.il/~wolf/deeplearningmeeting/pdfs/lecun-20141105-tau-intel-master-class.pdf
- deep learning throw away attributes
- it is highly efficient

(2017) Revisiting Unreasonable Effectiveness of Data in Deep Learning Era: https://research.google/pubs/pub46313/

(2020) The unreasonable effectiveness of deep learning in artificial intelligence: https://www.pnas.org/content/early/2020/01/23/1907373117

Where does labeling come from? https://www.youtube.com/watch?v=p0nR2YsCY_U and https://www.nytimes.com/2018/11/25/business/china-artificial-intelligence-labeling.html

What did deep learning KILL? How is it being revived?
- lost notion (mean) of parameters
- Capsule neural network

- Auto encoders, decoders, GANs...

Despite all the success, hopes, dreams, strategies... what if it turns out that as of yet, we don't have AI AT ALL (what we do have is 'IA' (intelligent augmentation))?


First, the current generation of AI does have problems, eg.:

bias in ML, eg. https://dzone.com/articles/aiml-bias-explained-with-examples ("racist linear algebra")
not that easy to replicate human knowledge, eg. https://spectrum.ieee.org/biomedical/diagnostics/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care
lack of transparency - an NN is a black-box, really, eg. https://towardsdatascience.com/interpretable-machine-learning-1dec0f2f3e6b
The PROBLEM with deep learning [what does Google's NN (via their Cloud Vision API - https://cloud.google.com/vision) 'think' these are? Below is the answer]:


easy foolability - eg. https://spectrum.ieee.org/cars-that-think/transportation/self-driving/three-small-stickers-on-road-can-steer-tesla-autopilot-into-oncoming-lane
SDCs' imperfections
danger of doing the wrong thing, eg. https://autonomousweapons.org/
...